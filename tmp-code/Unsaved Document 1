
import com.tuplejump.calliope.CasBuilder
val cas = CasBuilder.native.withColumnFamilyAndKeyColumns("cql3_test", "emp_read_test", "deptid").mergeRangesInMultiRangeSplit(256)

import org.apache.spark.SerializableWritable
import org.apache.hadoop.conf.Configuration

val sw = new SerializableWritable(cas.configuration)

import java.io._
val bos= new ByteArrayOutputStream
val oos = new ObjectOutputStream(bos)
oos.writeObject(sw)
val ba = bos.toByteArray

val bis = new ByteArrayInputStream(ba)

val ois = new ObjectInputStream(bis)
val conf = ois.readObject().asInstanceOf[SerializableWritable[Configuration]].value

import com.tuplejump.calliope.hadoop.ConfigHelper
import com.tuplejump.calliope.hadoop.cql3.CqlConfigHelper

ConfigHelper.getOutputRpcPort(conf)

CqlConfigHelper.getMultiRangeInputSplit(conf)

