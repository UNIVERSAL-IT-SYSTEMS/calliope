{"name":"Calliope","tagline":"Calliope is a library integrating Cassandra and Spark framework.","body":"Calliope\r\n========\r\nCalliope is a library providing an interface to consume data from Cassandra to spark and store RDDs from Spark to Cassandra.\r\n\r\nWhy Cassandra + Spark?\r\n----------------------\r\nCassandra + Spark is the match made in heaven! Spark with it's in memory mapreduce allows us to process data upto 10x faster than Hadoop MapReduce, opening doors to iterative map reduce, complex process chains in a plain and simple start and so much more. Spark did away with the complex setup and configuration required by Hadoop M/R in it's early days. Overall, it make big data crunching fun!\r\n\r\nThe only bottleneck now is the HDFS or worse HBASE, which are still used by many Spark developers to build the applications and providing a distributed data store to the RDDs. Setting up and maintaining HDFS and maintianing the cluster, requires effort and experience. All HDFS provides is a filesystem. Anything you put there is a file and will be read line by line. This may work for unstructured data, but not so much wth strutured one. The problem with both these solutions is htey are Hadoop! There I said it!!!\r\n\r\nCome in Cassandra, built on Dynamo's gossip with BigTable's column oriented storage, Cassandra provides a resilient fualt tollerant robust very high speed data store. Coming from the NoSQL family of databses, it provides flexible schema support, which makes it good for structured as well as unstructured data. Setting up and managing Cassandra cluster's is quick and easy.\r\n\r\nCassandra storage bckend with Spark will open many new avenues.\r\n\r\nWhy Calliope?\r\n------------\r\nSpark supports any Hadoop Input/Output provider and we know there is a Hadoop I/O for Cassandra, so I can simply use it! \r\nYes, sure you can, and for now Calliope uses the same. But contrary to the Hadoop I/O API which was designed for java and Hadoop way of doing things, Calliope provides a improved cleaner API to create and persist RDDs, without exposing you to the internals. In furutre we would like to move away from Hadoop I/O here and build our own fat-free alternative. But, don't worry, we won't change the API for that.\r\n\r\nEnough, talk, show me the Code\r\n------------------------------\r\nHere you go!\r\n\r\n###Reading from Cassandra\r\nTo read a **Column Family** names *Words* from a **keyspace** *casDemo* and create an RDD from it, here is the code required using Calliope, considering the **key** is a *String* and the **row** has all column names and values as *String*.\r\n\r\n```\r\nimport com.tuplejump.calliope.RichByteBuffer._\r\nimport com.tuplejump.calliope.Implicits._\r\nimport com.tuplejump.calliope.CasBuilder\r\n\r\nval cas = CasBuilder.thrift.with(\"casDemo\", \"Words\")\r\nval rdd = sc.cassandra[String, Map[String, String](cas)\r\n\r\n```\r\n\r\nAnd now you have a RDD[String, Map[String, String]]!\r\n\r\nTo fully appreciate the ease and terseness of the above code, I recomend you take a look at the the Cassandra example in Spark examples code.\r\n\r\n###Writing to Cassandra\r\nTo write an RDD[String, Map[String, String]] a **Column Family** names *Words* from a **keyspace** *casDemo* \r\n\r\n```\r\nimport com.tuplejump.calliope.RichByteBuffer._\r\nimport com.tuplejump.calliope.Implicits._\r\nimport com.tuplejump.calliope.CasBuilder\r\n\r\nval cas = CasBuilder.thrift.with(\"casDemo\", \"Words\")\r\nrdd.saveToCassandra(cas)\r\n```\r\n\r\n### More examples\r\nSee the test cases!\r\n\r\nTroubleshooting\r\n---------------\r\n\r\n* Why do I get a \"No Implicit View Defined for X => Y\" message while compiling?\r\n\r\nCalliope relies on Implicits to convert to and from ByteBuffer and structures around it to Usable data types. In case you have a key or value type that doesn't have a implicit convertor defined, you will have to write one of your own. Don't worry this is easy, just look at the test cases.\r\n\r\n* Why do I get a ByteBuffer not Serializable error while the computing on RDD created from Cassandra?\r\n\r\nYou **should** give Type Parameters to sc.cassandra method and provide appropriate transformers for that.","google":"UA-42063240-2","note":"Don't delete this file! It's used internally to help with page regeneration."}